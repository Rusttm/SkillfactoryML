{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e764b52a",
   "metadata": {},
   "source": [
    "p10_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a6906c",
   "metadata": {},
   "source": [
    "В следующих заданиях будет использоваться датасет boston из sklearn.datasets.\n",
    "\n",
    "Оставьте последние 25% объектов для контроля качества, разделив X и y на X_train, y_train и X_test, y_test с помощью train_test_split(X, y, train_size = 0.75, shuffle=False).\n",
    "\n",
    "Целью заданий будет реализовать простой вариант градиентного бустинга над регрессионными деревьями для случая квадратичной функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9553f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_boston()\n",
    "# Подготовить данные\n",
    "X, y = data['data'], data['target']\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.75, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2826222",
   "metadata": {},
   "source": [
    "Задание 6.4.2\n",
    "\n",
    "0.0/2.0 points (graded)\n",
    "Заведите массив для объектов DecisionTreeRegressor (будем их использовать в качестве базовых алгоритмов) и для вещественных чисел (это будут коэффициенты перед базовыми алгоритмами).\n",
    "\n",
    "В цикле обучите последовательно 50 решающих деревьев с параметрами max_depth=5 и random_state=139 (остальные параметры — по умолчанию). В бустинге зачастую используются сотни и тысячи деревьев, но мы ограничимся 50, чтобы алгоритм работал быстрее, и его было проще отлаживать (т.к. цель задания разобраться, как работает метод). Каждое дерево должно обучаться на одном и том же множестве объектов, но ответы, которые учится прогнозировать дерево, будут меняться в соответствии с полученным в задании 1 правилом.\n",
    "\n",
    "Попробуйте для начала всегда брать коэффициент равным . Обычно оправдано выбирать коэффициент значительно меньшим — порядка  или , но т.к. в нашем учебном примере на стандартном датасете будет всего  деревьев, возьмём для начала шаг побольше.\n",
    "\n",
    "В процессе реализации обучения вам потребуется функция, которая будет вычислять прогноз построенной на данный момент композиции деревьев на выборке X:\n",
    "\n",
    "def gbm_predict(X): return [sum([coeff * algo.predict([x])[0] for algo, coeff in zip(base_algorithms_list, coefficients_list)]) for x in X]\n",
    "(считаем, что base_algorithms_list — список с базовыми алгоритмами, coefficients_list — список с коэффициентами перед алгоритмами).\n",
    "\n",
    "Эта же функция поможет вам получить прогноз на контрольной выборке и оценить качество работы вашего алгоритма с помощью mean_squared_error в sklearn.metrics.\n",
    "\n",
    "Возведите результат в степень , чтобы получить RMSE. Полученное значение RMSE введите в поле для ответа:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4accd11e",
   "metadata": {},
   "source": [
    "ответ 5.317530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216dcbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RANDOM_SEED = 139 \n",
    "coeff = 0.9\n",
    "base_algorithms_list = []\n",
    "coefficients_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbm_predict(X):\n",
    "    return [sum([coeff * algo.predict([x])[0] for algo, coeff in zip(base_algorithms_list, coefficients_list)]) for x in X] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee07a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree_model = DecisionTreeRegressor(max_depth=5, random_state=RANDOM_SEED)\n",
    "coefficients_list.append(0.9)\n",
    "base_algorithms_list.append(reg_tree_model.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7051e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_algorithms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e30ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(50):\n",
    "    reg_tree_model = DecisionTreeRegressor(max_depth=5, random_state=RANDOM_SEED)\n",
    "    y_pred = y_train - gbm_predict(X_train)\n",
    "    reg_tree_model.fit(X_train, y_pred)\n",
    "    base_algorithms_list.append(reg_tree_model)\n",
    "    alpha = 0.9 / (1.0 + i)\n",
    "    coefficients_list.append(alpha)\n",
    "    RMSE = mean_squared_error(y_true = y_valid, y_pred = gbm_predict(X_valid))**0.5\n",
    "    print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919f80c",
   "metadata": {},
   "source": [
    "Задание 6.4.5\n",
    "\n",
    "0.0/2.0 points (graded)\n",
    "Сравните получаемое с помощью градиентного бустинга качество с качеством работы линейной регрессии.\n",
    "\n",
    "Для этого обучите LinearRegression из sklearn.linear_model (с параметрами по умолчанию) на обучающей выборке и оцените для прогнозов полученного алгоритма на тестовой выборке RMSE.\n",
    "\n",
    "Полученное качество введите в поле для ответа.\n",
    "В данном примере качество работы простой модели должно было оказаться хуже, но не стоит забывать, что так бывает не всегда.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237519d5",
   "metadata": {},
   "source": [
    "ответ 8.254970"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70401ada",
   "metadata": {},
   "source": [
    "6.6. Стекинг. Практика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "545365ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier, ExtraTreesClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats.distributions import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ef3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_digits()\n",
    "X, y = dataset['data'], dataset['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20bbf84",
   "metadata": {},
   "source": [
    "Задание 6.6.1\n",
    "\n",
    "0.0/3.0 points (graded)\n",
    "В скринкасте мы разобрали схему генерации признаков в стекинге, когда для тестовой выборки алгоритм заново переобучался на всей тренировочной выборке. Реализуйте схему, когда вместо этого производится агрегация ответов всех обученных на фолдах классификаторов на тестовой выборке при помощи усреднения.\n",
    "\n",
    "Логика решения:\n",
    "1) Создадим X_meta_test, заполним его нулями (по аналогии с X_meta_train);\n",
    "2) Далее на каждом шаге, где мы обучаем folded_clf.fit (X_fold_train, y_fold_train) и его предсказания на X_fold_predict запихиваем в X_meta_train[predict_fold_index], добавим ещё одну строку, где в X_meta_test будем добавлять предсказания вероятностей folded_clf на X_test. Их можно сразу складывать друг с другом или сохранить много массивов, тогда в конце их нужно будет все сложить, а потом делить на количество сплитов (количество массивов равно количеству сплитов в кросс-валидации);\n",
    "3) После цикла останется только усреднить все эти массивы — это и будет наш X_meta_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8390fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meta_feature_mean(clf, X_train, X_test, y_train, cv):\n",
    "    \"\"\"    Эта функция подсчитывает признаки для мета-классификатора.     Они являются вероятностями классов при решении задачи многоклассовой классификации.    :arg clf: классификатор    :args X_train, y_train: обучающая выборка    :arg X_test: признаки тестовой выборки    :arg cv: класс, генерирующий фолды (KFold)    :returns X_meta_train, X_meta_test: новые признаки для обучающей и тестовой выборок    \"\"\"\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    X_meta_train = np.zeros((len(X_train), n_classes), dtype=np.float32)\n",
    "    for train_fold_index, predict_fold_index in cv.split(X_train):\n",
    "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
    "        y_fold_train = y_train[train_fold_index]\n",
    "\n",
    "        folded_clf = clone(clf)\n",
    "        folded_clf.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)\n",
    "\n",
    "    meta_clf = clone(clf)\n",
    "    meta_clf.fit(X_train, y_train)\n",
    "\n",
    "    X_meta_test = meta_clf.predict_proba(X_test)\n",
    "\n",
    "    return X_meta_train, X_meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d86d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meta_feature_mean(clf, X_train, X_test, y_train, cv):\n",
    "    \"\"\"\n",
    "    Эта функция подсчитывает признаки для мета-классификатора. \n",
    "    Они являются вероятностями классов при решении задачи многоклассовой классификации.\n",
    "\n",
    "    :arg clf: классификатор\n",
    "    :args X_train, y_train: обучающая выборка\n",
    "    :arg X_test: признаки тестовой выборки\n",
    "    :arg cv: класс, генерирующий фолды (KFold)\n",
    "\n",
    "    :returns X_meta_train, X_meta_test: новые признаки для обучающей и тестовой выборок\n",
    "    \"\"\"\n",
    "# Напишите ваш код ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a676d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n",
    "    \n",
    "    X_meta_train = np.zeros_like(y_train, dtype=np.float32)\n",
    "    for train_fold_index, predict_fold_index in cv.split(X_train):\n",
    "        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n",
    "        y_fold_train = y_train[train_fold_index]\n",
    "        \n",
    "        folded_clf = clone(clf)\n",
    "        folded_clf.fit(X_fold_train, y_fold_train)\n",
    "        X_meta_train[predict_fold_index] = folded_clf.predict_proba(X_fold_predict)[:, 1]\n",
    "    \n",
    "    meta_clf = clone(clf)\n",
    "    meta_clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_meta_test = meta_clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return X_meta_train, X_meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5524e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
