{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f72997",
   "metadata": {},
   "source": [
    "3.2. Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a434ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "da5cd837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2cb19052",
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = pd.read_csv('data/mycar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "bcd0ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = myData.iloc[:,:-1].values\n",
    "Y = myData.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8d12a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f6521f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1c5e1416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "myModel = LinearRegression() #Обозначаем, что наша модель - линейная регрессия\n",
    "myModel.fit(X_train,Y_train) #обучаем модель на обучающих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e31a539a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34.31953578, 47.91644101, 27.52108317, 58.11411992, 41.11798839,\n",
       "       13.92417795, 51.31566731, 34.31953578, 58.11411992, 27.52108317,\n",
       "       37.71876209, 30.92030948, 41.11798839, 75.11025145, 24.12185687])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = myModel.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17154caa",
   "metadata": {},
   "source": [
    "3.5. Линейная регрессия. Практика №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a1f0be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d234e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#certificates\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "aa238b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Theta function\n",
    "def linreg_linear(X, y):\n",
    "    xTrans = X.T\n",
    "    matrix = xTrans.dot(X)\n",
    "    matrix = np.linalg.inv(matrix)\n",
    "    matrix = matrix.dot(xTrans)\n",
    "    matrix = matrix.dot(y)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2112089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подготавливаем данные и вычисляем параметр :\n",
    "data = load_boston()\n",
    "dataCalifornia = fetch_california_housing()\n",
    "X, y = data['data'], data['target']\n",
    "# create ones array  [1,1,1,1 ...] from X rows and create from it new column \n",
    "e = np.ones(X.shape[0])[:, np.newaxis]\n",
    "# Join a sequence of arrays along a new axis.\n",
    "X = np.hstack([e, X])\n",
    "\n",
    "theta = linreg_linear(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "71bc75b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.64594884e+01, -1.08011358e-01,  4.64204584e-02,  2.05586264e-02,\n",
       "        2.68673382e+00, -1.77666112e+01,  3.80986521e+00,  6.92224640e-04,\n",
       "       -1.47556685e+00,  3.06049479e-01, -1.23345939e-02, -9.52747232e-01,\n",
       "        9.31168327e-03, -5.24758378e-01])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "32d8f292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.867455573954125\n"
     ]
    }
   ],
   "source": [
    "lenth_vect = 0\n",
    "for x in theta:\n",
    "    lenth_vect += x*x\n",
    "print(lenth_vect**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e502d431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d3bca52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.867455573954125"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(theta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7b71a855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ymax 50.0, Xmax 711.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Ymax {y.max()}, Xmax {X.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8f7cb6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c712a608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(X.shape[0])[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9df7bc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(X.shape[0])[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "15fed2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем предсказание и посчитаем метрики:\n",
    "y_pred = X.dot(theta)\n",
    "\n",
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e8d8a8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "#для полноразмерного обучения -полной выборки\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8abc10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Давайте разобьём выборку на train/valid, вычислим , сделаем предсказания и посчитаем ошибки MSE и RMSE:\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = linreg_linear(X_train, y_train)\n",
    "y_valid_pred = X_valid.dot(theta)\n",
    "y_train_pred = X_train.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ad050326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 29.02, RMSE = 5.39\n"
     ]
    }
   ],
   "source": [
    "#для тестовой выборки\n",
    "print_regression_metrics(y_valid, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1c89ee63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 20.54, RMSE = 4.53\n"
     ]
    }
   ],
   "source": [
    "#для тренировочной выборки\n",
    "print_regression_metrics(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7a67b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Реализуем функцию вычисления градиента функции  и шаг градиентного спуска:\n",
    "def calc_mse_gradient(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    y_hat = X.dot(theta)\n",
    "    grad = 1. / n * X.transpose().dot(y_hat - y)\n",
    "    return grad\n",
    "\n",
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "83d32d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сделаем процедуру оптимизации:\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7f27a9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Оптимизируем параметр линейной регрессии  на всех данных:\n",
    "m = X.shape[1]\n",
    "theta = optimize(X, y, calc_mse_gradient, np.ones(m), 0.001, 100)\n",
    "np.linalg.norm(theta) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605c490",
   "metadata": {},
   "source": [
    "#Градиент получился очень большой, у нас вышло переполнение, и  выдала значения nan. Для того чтобы этого избежать, нужно применить стандартную нормализацию:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a43b7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data['data'], data['target']\n",
    "X_norm = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "y_norm = (y - y.mean(axis=0)) / y.std(axis=0)\n",
    "#нормализуем\n",
    "e = np.ones(X_norm.shape[0])[: , np.newaxis]\n",
    "X_norm = np.hstack([e, X_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c7279bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.698188183235512"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = optimize(X_norm, y, calc_mse_gradient, np.ones(X_norm.shape[1]), 0.01, 10000)\n",
    "np.linalg.norm(theta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ec8bd03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "#Сделаем предсказание, посчитаем значение ошибок:\n",
    "y_pred = X_norm.dot(theta)\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e863b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c205d37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 40.23, RMSE = 6.34\n"
     ]
    }
   ],
   "source": [
    "#Разобьём выборку на train/valid, оптимизируем , сделаем предсказания и посчитаем ошибки MSE и RMSE:\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_norm, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_mse_gradient, np.ones(X_norm.shape[1]), 0.01, 5000)\n",
    "y_pred = X_valid.dot(theta)\n",
    "\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ef3bba12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.750440913969214"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(theta) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dea172",
   "metadata": {},
   "source": [
    "# Задание 3.5.1\n",
    "\n",
    "2.0/2.0 points (graded)\n",
    "Реализуйте матричную линейную регрессию. Какой получился RMSE?\n",
    "Ответ округлите до сотых, пример ввода: 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "9d8fb7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Theta function\n",
    "def linreg_linear(X, y):\n",
    "    xTrans = X.T\n",
    "    matrix = xTrans.dot(X)\n",
    "    matrix = np.linalg.inv(matrix)\n",
    "    matrix = matrix.dot(xTrans)\n",
    "    matrix = matrix.dot(y)\n",
    "    return matrix\n",
    "\n",
    "#Подготавливаем данные и вычисляем параметр :\n",
    "data = load_boston()\n",
    "dataCalifornia = fetch_california_housing()\n",
    "X, y = data['data'], data['target']\n",
    "# create ones array  [1,1,1,1 ...] from X rows and create from it new column \n",
    "e = np.ones(X.shape[0])[:, np.newaxis]\n",
    "# Join a sequence of arrays along a new axis.\n",
    "X = np.hstack([e, X])\n",
    "\n",
    "theta = linreg_linear(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e61fc1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "# Сделаем предсказание и посчитаем метрики:\n",
    "y_pred = X.dot(theta)\n",
    "\n",
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
    "#для полноразмерного обучения -полной выборки\n",
    "print_regression_metrics(y, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde5d123",
   "metadata": {},
   "source": [
    "### ответ RMSE = 4.68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d0e656",
   "metadata": {},
   "source": [
    "# Задание 3.5.2\n",
    "\n",
    "2.0/2.0 points (graded)\n",
    "Постройте модель при помощи sklearn. Используйте параметры по умолчанию, обучите на всей выборке и посчитайте RMSE.\n",
    "Ответ округлите до сотых, пример ввода: 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2e0fdeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5aa380d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.89, RMSE = 4.68\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)\n",
    "y_pred = reg.predict(X)\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "71fb721c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -1.08011358e-01,  4.64204584e-02,  2.05586264e-02,\n",
       "        2.68673382e+00, -1.77666112e+01,  3.80986521e+00,  6.92224640e-04,\n",
       "       -1.47556685e+00,  3.06049479e-01, -1.23345939e-02, -9.52747232e-01,\n",
       "        9.31168327e-03, -5.24758378e-01])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "ad0c218b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.64594884e+01, -1.08011358e-01,  4.64204584e-02,  2.05586264e-02,\n",
       "        2.68673382e+00, -1.77666112e+01,  3.80986521e+00,  6.92224640e-04,\n",
       "       -1.47556685e+00,  3.06049479e-01, -1.23345939e-02, -9.52747232e-01,\n",
       "        9.31168327e-03, -5.24758378e-01])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b66198a",
   "metadata": {},
   "source": [
    "### ответ 4,68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a4aaf3",
   "metadata": {},
   "source": [
    "# Задание 3.5.3\n",
    "\n",
    "2.0/2.0 points (graded)\n",
    "Чему равно наибольшее стандартное отклонение у признаков?\n",
    "\n",
    "Ответ округлите до сотых. Пример ввода: 5.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a5ddadb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168.3704950393814"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X, axis=0).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a735e2cc",
   "metadata": {},
   "source": [
    "### ответ 168.37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb60631",
   "metadata": {},
   "source": [
    "# Задание 3.5.4\n",
    "\n",
    "2.0/2.0 points (graded)\n",
    "Обучите регрессию без дополнительного столбца единиц. Какой получился RMSE?\n",
    "Ответ округлите до сотых. Пример ввода: 5.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "02b47c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Theta function\n",
    "def linreg_linear(X, y):\n",
    "    xTrans = X.T\n",
    "    matrix = xTrans.dot(X)\n",
    "    matrix = np.linalg.inv(matrix)\n",
    "    matrix = matrix.dot(xTrans)\n",
    "    matrix = matrix.dot(y)\n",
    "    return matrix\n",
    "\n",
    "#Подготавливаем данные и вычисляем параметр :\n",
    "data = load_boston()\n",
    "dataCalifornia = fetch_california_housing()\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "theta = linreg_linear(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "fd3736ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 24.17, RMSE = 4.92\n"
     ]
    }
   ],
   "source": [
    "# Сделаем предсказание и посчитаем метрики:\n",
    "y_pred = X.dot(theta)\n",
    "\n",
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
    "#для полноразмерного обучения -полной выборки\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97265802",
   "metadata": {},
   "source": [
    "### ответ 4.68 (ошибка курса)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6fb67f",
   "metadata": {},
   "source": [
    "# Задание 3.5.5\n",
    "\n",
    "2.0/2.0 points (graded)\n",
    "Очистите данные от строк, где значение признака  В меньше 50. Какой получился RMSE?\n",
    "Ответ округлите до сотых, пример ввода: 5.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d1bb70c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Theta function\n",
    "def linreg_linear(X, y):\n",
    "    xTrans = X.T\n",
    "    matrix = xTrans.dot(X)\n",
    "    matrix = np.linalg.inv(matrix)\n",
    "    matrix = matrix.dot(xTrans)\n",
    "    matrix = matrix.dot(y)\n",
    "    return matrix\n",
    "\n",
    "#Подготавливаем данные и вычисляем параметр :\n",
    "data = load_boston()\n",
    "dataCalifornia = fetch_california_housing()\n",
    "X, y = data['data'][data['data'][:, 11]>=50], data['target'][data['data'][:, 11]>=50]\n",
    "# create ones array  [1,1,1,1 ...] from X rows and create from it new column \n",
    "e = np.ones(X.shape[0])[:, np.newaxis]\n",
    "# Join a sequence of arrays along a new axis.\n",
    "X = np.hstack([e, X])\n",
    "theta = linreg_linear(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f0dd4fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 21.79, RMSE = 4.67\n"
     ]
    }
   ],
   "source": [
    "# Сделаем предсказание и посчитаем метрики:\n",
    "y_pred = X.dot(theta)\n",
    "\n",
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
    "#для полноразмерного обучения -полной выборки\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5959fcd",
   "metadata": {},
   "source": [
    "### ответ 4.68 (ошибка курса)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74626012",
   "metadata": {},
   "source": [
    "# Задание 3.5.6\n",
    "\n",
    "2.0/2.0 points (graded)\n",
    "Нормализуйте признаки и обучите линейную регрессию матричным методом. Какой получился RMSE?\n",
    "Ответ округлите до сотых, пример ввода: 5.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6deadb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Theta function\n",
    "def linreg_linear(X, y):\n",
    "    xTrans = X.T\n",
    "    matrix = xTrans.dot(X)\n",
    "    matrix = np.linalg.inv(matrix)\n",
    "    matrix = matrix.dot(xTrans)\n",
    "    matrix = matrix.dot(y)\n",
    "    return matrix\n",
    "\n",
    "#Подготавливаем данные и вычисляем параметр :\n",
    "data = load_boston()\n",
    "dataCalifornia = fetch_california_housing()\n",
    "X, y = data['data'], data['target']\n",
    "#X_norm = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "X_norm = MinMaxScaler().fit_transform(X, y)\n",
    "y_norm = (y - y.mean(axis=0)) / y.std(axis=0)\n",
    "\n",
    "theta = linreg_linear(X_norm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "6de09ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 27.47, RMSE = 5.24\n"
     ]
    }
   ],
   "source": [
    "# Сделаем предсказание и посчитаем метрики:\n",
    "y_pred = X_norm.dot(theta)\n",
    "\n",
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
    "#для полноразмерного обучения -полной выборки\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "7d25754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 27.47, RMSE = 5.24\n"
     ]
    }
   ],
   "source": [
    "#вариант 2\n",
    "X2 = pd.DataFrame(X)\n",
    "def normalization_df(X):\n",
    "    result = X.copy()\n",
    "    for column_name in X.columns:\n",
    "        max_value = X[column_name].max()\n",
    "        min_value = X[column_name].min()\n",
    "        std_value = X[column_name].mean()\n",
    "        if max_value == min_value:\n",
    "            result[column_name] = 1\n",
    "        else: \n",
    "            result[column_name] = (X[column_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "X_norm2 = normalization_df(X2)\n",
    "theta2 = linreg_linear(X_norm2, y)\n",
    "\n",
    "# Сделаем предсказание и посчитаем метрики:\n",
    "y_pred = X_norm2.dot(theta2)\n",
    "\n",
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
    "#для полноразмерного обучения -полной выборки\n",
    "print_regression_metrics(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09969b00",
   "metadata": {},
   "source": [
    "### ответ 4.68 (ошибка курса)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
